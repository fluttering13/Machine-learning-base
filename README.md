# Machine-learning
來說說一些 從數據科學角度出發去看ML 去看這些oracle 不能僅僅只是煉丹爐或者魔法

## 機器學習(What is machine learning?)
在切入主題之前，我們來定義一下什麼是學習？
是把所有問題的答案都背下來？是個學習嗎？
很明顯，從小到大如果你有朋友是這樣，也許它會過得很辛苦。
上述的過程也只能說是一個資料庫，什麼是學習呢，在於使用這些資料的能力。
你會看到這些資料是怎麼彼此建立起他們的連結，
例如說我現在資料裡面有 大象、猴子、企鵝
我們試著去建立起他們的屬性，透過觀察，我們可以知道這些都是哺乳類動物，他們都在動物園裡面
這些資料跟資料之間可以透過函數的連結，幫助我們去找到他們之間的關係
如果重建這些關係，我們就說是學習的一個過程

但往往我們可能不太清楚現實世界的關係是長什麼樣子，所以我們會有一個hypothesis set
例如說我們把動物這樣的概念當成一個hypothesis set
數據上你今天知道了 大象、猴子、企鵝
所以你試圖去刻劃動物這樣的集合，
所以你是去看他們共有的器官
他們有 眼睛、鼻子、嘴巴......等等。

得知現有的數據 (大象、猴子、企鵝)
在有目標函數的情況 (共有的器官)
試圖去找到一個最佳化的參數 (眼睛、鼻子、嘴巴)
來描述你有興趣的模型 (動物)

所以很自然的，我們會問說，要怎麼去建立起一個模式去找到這樣的函數關係？
$$f(X) = Y$$
在現今常用的方式我們試圖去寫下一個類線性的方程
也就是所謂的類神經元網路
$$\alpha W{\rm{X + b = Y}}$$

$$
\alpha 
\left[
\begin{matrix}
    w_{11} & ... & w_{1n} \\\\
    ... & ... & ... \\\\
    w_{m1} & ... & w_{mn}
\end{matrix}
\right]
\left[
\begin{matrix}
x_{1}\\\\
...\\\\
x_{m}
\end{matrix}
\right]
+
\left[
\begin{matrix}
b_{1}\\\\
...\\\\
b_{m}
\end{matrix}
\right]
\leq
\left[
\begin{matrix}
y_{1}\\\\
...\\\\
y_{m}
\end{matrix}
\right]
$$

其中 $\alpha$ 可以是一個非線性的方程
在這邊我們只是寫下他們的形式，其中會遇到各式各樣的問題
如：
優化怎麼做？
目標方程要怎麼選？
要選什麼樣的 $\alpha$ ?

再來我們從一些數據科學的角度來進行切入
## 有限數據
往往我們是想要追求理想上的模型
但我們今天只能夠從真實數據拿到的是有限的數量
這邊會衍生一些問題
我要拿多少的數據才能能夠很好的去回答一個問題？
此處我們來引入一個Hoeffding不等式來說明
假設我們從一個母體作抽樣，總共抽N筆資料，
我們把預測正確的結果叫T，所佔的比例為 $\mu$，
失敗的叫F，所佔的比例為 $\nu$
我們令這兩的比例的誤差為 $\epsilon$
$$P[{\rm{|}}\mu {\rm{ - }}\nu {\rm{| < }}\varepsilon ] \ge 2\exp \left( { - 2{\varepsilon ^2}N} \right)$$
假如今天取了1000筆的資料，我們允許這個誤差可以到7%
我們會得到機率為0.00011090319886435389 約為0.01%
我們取了10000筆，這個機率可以降到10^-43
只要我們取了足夠多，一定是更有信心去做預測的


## Laplace 準確定性概念(Laplace's quasi-deterministic conception)
所有的隨機模型(古典)，都可以用函數模型來進行表示

